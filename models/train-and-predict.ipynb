{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 57236,
     "databundleVersionId": 7230081,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30615,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-12-09T12:20:07.696870Z",
     "iopub.execute_input": "2023-12-09T12:20:07.697449Z",
     "iopub.status.idle": "2023-12-09T12:20:08.187508Z",
     "shell.execute_reply.started": "2023-12-09T12:20:07.697399Z",
     "shell.execute_reply": "2023-12-09T12:20:08.186196Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pickle\n",
    "import torch\n",
    "import xgboost as xgb"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-09T12:23:39.439674Z",
     "iopub.execute_input": "2023-12-09T12:23:39.440147Z",
     "iopub.status.idle": "2023-12-09T12:23:43.209587Z",
     "shell.execute_reply.started": "2023-12-09T12:23:39.440109Z",
     "shell.execute_reply": "2023-12-09T12:23:43.208347Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def split_date(data: DataFrame, col: str):\n",
    "    \"\"\"\n",
    "    拆分时间\n",
    "    :param data:需要拆分的数据\n",
    "    :param col: 时间所在的列\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    data['year'] = data[col].apply(lambda x: x.year)\n",
    "    data['month'] = data[col].apply(lambda x: x.month)\n",
    "    data['day'] = data[col].apply(lambda x: x.day)\n",
    "    data['hour'] = data[col].apply(lambda x: x.hour)\n",
    "    return data\n",
    "\n",
    "def merge_data(train, train_history, client, gas_prices, electricity, historical_weather, forecast_weather, station):\n",
    "    \"\"\"处理train数据\"\"\"\n",
    "    if 'datetime' in train.columns:\n",
    "        pass\n",
    "    else:\n",
    "        train.rename(columns={'prediction_datetime': 'datetime'}, inplace=True)\n",
    "    train = split_date(train, 'datetime')  # 拆分时间\n",
    "\n",
    "    \"\"\"处理train_history数据\"\"\"\n",
    "    train_history['datetime'] = train_history['datetime'].apply(lambda x: x + pd.Timedelta(2, 'D'))\n",
    "    train_history.rename(columns={'target': 'target_used'}, inplace=True)\n",
    "\n",
    "    \"\"\"处理client数据\"\"\"\n",
    "    client['datetime'] = client['date'].apply(lambda x: x+pd.Timedelta(2, 'D'))  # 将day向前移两天\n",
    "    client = split_date(client, 'datetime')\n",
    "    client.drop(columns=['hour', 'datetime', 'date'], inplace=True)\n",
    "\n",
    "    \"\"\"处理gas_prices数据\"\"\"\n",
    "    gas_prices['datetime'] = gas_prices['forecast_date'].apply(lambda x: x + pd.Timedelta(1, 'D'))\n",
    "    gas_prices = split_date(gas_prices, 'datetime')\n",
    "    gas_prices.drop(columns=['datetime', 'forecast_date', 'hour'], inplace=True)\n",
    "\n",
    "    \"\"\"处理electricity数据\"\"\"\n",
    "    electricity['datetime'] = electricity['forecast_date'].apply(lambda x: x + pd.Timedelta(1, 'D'))\n",
    "    electricity.drop(columns=['forecast_date'], inplace=True)\n",
    "\n",
    "    \"\"\"处理historical_weather数据\"\"\"\n",
    "    historical_weather['datetime'] = historical_weather['datetime'].apply(lambda x: x + pd.Timedelta(37, 'H'))\n",
    "    historical_weather['latitude'] = historical_weather['latitude'].round(1)   # 将经纬度取一位小数\n",
    "    historical_weather['longitude'] = historical_weather['longitude'].round(1)\n",
    "    station.loc[:, 'longitude'] = station.loc[:, 'longitude'].round(1)\n",
    "    station.loc[:, 'latitude'] = station.loc[:, 'latitude'].round(1)\n",
    "    # 与station数据按照经纬度和时间拼接\n",
    "    historical_weather = pd.merge(left=historical_weather, right=station, how='left', on=['latitude', 'longitude'])\n",
    "    historical_weather.dropna(subset='county', inplace=True)\n",
    "    historical_weather.drop(columns=['latitude', 'longitude'], inplace=True)\n",
    "    # 由于一个county对应多个天气站点，将同一个county同一时间的数据平均\n",
    "    historical_weather = historical_weather.groupby(by=['datetime', 'county']).mean()\n",
    "\n",
    "    \"\"\"处理forecast_weather数据\"\"\"\n",
    "    forecast_weather = forecast_weather[forecast_weather['hours_ahead'] >= 24]\n",
    "    forecast_weather.loc[:, 'longitude'] = forecast_weather.loc[:, 'longitude'].round(1)\n",
    "    forecast_weather.loc[:, 'latitude'] = forecast_weather.loc[:, 'latitude'].round(1)\n",
    "    forecast_weather = pd.merge(left=forecast_weather, right=station, on=['latitude', 'longitude'])\n",
    "    # 去除缺失值以及删除无用列\n",
    "    forecast_weather.dropna(subset='county', inplace=True)\n",
    "    forecast_weather.drop(\n",
    "        columns=['latitude', 'longitude', 'hours_ahead'],\n",
    "        inplace=True)\n",
    "    # 将forecast列索引重命名，以防止合并后与historical重名\n",
    "    forecast_cols_new = {}\n",
    "    forecast_cols = forecast_weather.columns\n",
    "    for index in forecast_cols:\n",
    "        if index == 'forecast_datetime':\n",
    "            index_new = 'datetime'\n",
    "        elif index == 'county':\n",
    "            index_new = index\n",
    "        else:\n",
    "            index_new = str(index) + '_fw'\n",
    "        forecast_cols_new[index] = index_new\n",
    "    forecast_weather.rename(columns=forecast_cols_new, inplace=True)\n",
    "    # 去除时间UTC值\n",
    "    forecast_weather['datetime'] = pd.to_datetime(forecast_weather.datetime).dt.tz_localize(None)\n",
    "    # 由于一个county对应多个天气站点，将同一个county同一时间的数据平均\n",
    "    forecast_weather = forecast_weather.groupby(by=['datetime', 'county']).mean()\n",
    "\n",
    "    \"\"\"开始拼接数据\"\"\"\n",
    "    data = pd.merge(left=train, right=train_history, how='left', on=['datetime', 'county', 'is_business', 'product_type',\n",
    "                                                                     'is_consumption'])\n",
    "    data = pd.merge(left=data, right=client, how='left', on=['product_type', 'county',\n",
    "                                                             'is_business', 'year', 'month', 'day'])\n",
    "    data = pd.merge(left=data, right=gas_prices, how='left', on=['year', 'month', 'day'])\n",
    "    data = pd.merge(left=data, right=electricity, how='left', on='datetime')\n",
    "    data = pd.merge(left=data, right=historical_weather, how='left', on=['datetime', 'county'])\n",
    "    data = pd.merge(left=data, right=forecast_weather, how='left', on=['datetime', 'county'])\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_data(train, train_history, client, gas_prices, electricity, historical_weather, forecast_weather,\n",
    "                      station, is_train=True):\n",
    "    \"\"\"加载数据\"\"\"\n",
    "    data = merge_data(train, train_history, client, gas_prices, electricity, historical_weather, forecast_weather,\n",
    "                      station)\n",
    "    # 删除缺失值\n",
    "    data.dropna(how='any', inplace=True)\n",
    "    # 删除多余列\n",
    "    data.drop(columns=['datetime'], inplace=True)\n",
    "    # one-hot编码\n",
    "    data = pd.get_dummies(data, columns=['is_business', 'product_type', 'is_consumption'], dtype=float)\n",
    "    print(data.columns)\n",
    "    print(data)\n",
    "    # 生成nparray数组\n",
    "    row_id = data['row_id']\n",
    "    row_id = np.array(row_id)\n",
    "    if is_train:             # 删除多余列\n",
    "        X = data.drop(columns=['row_id', 'target'])\n",
    "        X = np.array(X)\n",
    "        print('X.shape', X.shape)\n",
    "        Y = data['target']\n",
    "        Y = np.array(Y)\n",
    "        output = (row_id, X, Y)\n",
    "        with open(\"train_data.pkl\", 'wb') as f:\n",
    "            pickle.dump(output, f)\n",
    "    else:\n",
    "        X = data.drop(columns=['row_id'])\n",
    "        X = np.array(X)\n",
    "        print('X.shape', X.shape)\n",
    "        output = (row_id, X)\n",
    "        with open(\"test_data.pkl\", 'wb') as f:\n",
    "            pickle.dump(output, f)\n",
    "    return output"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2023-12-09T12:20:08.197978Z",
     "iopub.execute_input": "2023-12-09T12:20:08.199103Z",
     "iopub.status.idle": "2023-12-09T12:20:08.239199Z",
     "shell.execute_reply.started": "2023-12-09T12:20:08.199061Z",
     "shell.execute_reply": "2023-12-09T12:20:08.237946Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 所用到的列\n",
    "train_cols = ['county', 'target', 'is_business', 'product_type', 'is_consumption', 'datetime', 'row_id']\n",
    "test_cols = ['county', 'is_business', 'product_type', 'is_consumption', 'datetime', 'row_id']\n",
    "train_history_cols = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']\n",
    "client_cols = ['product_type', 'county', 'eic_count', 'installed_capacity', 'is_business', 'date']\n",
    "gas_cols = ['forecast_date', 'lowest_price_per_mwh', 'highest_price_per_mwh']\n",
    "electricity_cols = ['forecast_date', 'euros_per_mwh']\n",
    "forecast_cols = ['latitude', 'longitude', 'hours_ahead', 'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'forecast_datetime', 'direct_solar_radiation', 'surface_solar_radiation_downwards', 'snowfall', 'total_precipitation']\n",
    "historical_cols = ['datetime', 'temperature', 'dewpoint', 'rain', 'snowfall', 'surface_pressure','cloudcover_total','cloudcover_low','cloudcover_mid','cloudcover_high','windspeed_10m','winddirection_10m','shortwave_radiation','direct_solar_radiation','diffuse_radiation','latitude','longitude']\n",
    "station_cols = ['longitude', 'latitude', 'county']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-09T12:20:08.243194Z",
     "iopub.execute_input": "2023-12-09T12:20:08.244501Z",
     "iopub.status.idle": "2023-12-09T12:20:08.255857Z",
     "shell.execute_reply.started": "2023-12-09T12:20:08.244448Z",
     "shell.execute_reply": "2023-12-09T12:20:08.254546Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/train.csv', parse_dates=['datetime'], usecols=train_cols)\n",
    "train_history = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/train.csv', parse_dates=['datetime'], usecols=train_history_cols)\n",
    "client = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/client.csv', parse_dates=['date'], usecols=client_cols)\n",
    "gas_prices = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/gas_prices.csv', parse_dates=['forecast_date'], usecols=gas_cols)\n",
    "electricity = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/electricity_prices.csv', parse_dates=['forecast_date'], usecols=electricity_cols)\n",
    "historical_weather = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/historical_weather.csv', parse_dates=['datetime'],\n",
    "                                     usecols=historical_cols)\n",
    "forecast_weather = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/forecast_weather.csv', parse_dates=['forecast_datetime'],\n",
    "                                   usecols=forecast_cols)\n",
    "station = pd.read_csv('/kaggle/input/predict-energy-behavior-of-prosumers/weather_station_to_county_mapping.csv', usecols=station_cols)\n",
    "row_id, X, Y = load_data(train, train_history, client, gas_prices, electricity, historical_weather, forecast_weather, station)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-09T12:20:08.257416Z",
     "iopub.execute_input": "2023-12-09T12:20:08.257755Z",
     "iopub.status.idle": "2023-12-09T12:23:00.763074Z",
     "shell.execute_reply.started": "2023-12-09T12:20:08.257723Z",
     "shell.execute_reply": "2023-12-09T12:23:00.761709Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_train_test(X, Y, seed, rate):\n",
    "    idx = int(rate * X.shape[0])\n",
    "    X_train = X[:idx]\n",
    "    Y_train = Y[:idx]\n",
    "    X_test = X[idx:]\n",
    "    Y_test = Y[idx:]\n",
    "    shuffled_indices = np.arange(X_train.shape[0])\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    X_train, Y_train = X_train[shuffled_indices], Y_train[shuffled_indices]\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "(X_train, y_train), (X_test, y_test) = make_train_test(X, Y, 1, 0.7)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "clf = xgb.XGBRegressor(\n",
    "                        device = device,\n",
    "                        objective='reg:absoluteerror',\n",
    "                        n_estimators = 2 if False else 1500,\n",
    "                        early_stopping_rounds=100\n",
    "                       )\n",
    "clf.fit(X = X_train,\n",
    "        y = y_train,\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)],\n",
    "        verbose = True\n",
    "       )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-09T12:23:48.031305Z",
     "iopub.execute_input": "2023-12-09T12:23:48.031980Z",
     "iopub.status.idle": "2023-12-09T12:29:50.892819Z",
     "shell.execute_reply.started": "2023-12-09T12:23:48.031943Z",
     "shell.execute_reply": "2023-12-09T12:29:50.891749Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Early stopping on best iteration #{clf.best_iteration} with MAE error on validation set of {clf.best_score:.2f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-09T12:30:04.490268Z",
     "iopub.execute_input": "2023-12-09T12:30:04.491431Z",
     "iopub.status.idle": "2023-12-09T12:30:04.498096Z",
     "shell.execute_reply.started": "2023-12-09T12:30:04.491386Z",
     "shell.execute_reply": "2023-12-09T12:30:04.496775Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    " clf.predict(X_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-09T12:39:40.943118Z",
     "iopub.execute_input": "2023-12-09T12:39:40.943573Z",
     "iopub.status.idle": "2023-12-09T12:39:42.519091Z",
     "shell.execute_reply.started": "2023-12-09T12:39:40.943539Z",
     "shell.execute_reply": "2023-12-09T12:39:42.517884Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
